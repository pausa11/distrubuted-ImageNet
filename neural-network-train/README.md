# Entrenamiento Distribuido con Algoritmo Gossip

Este directorio contiene scripts para entrenar redes neuronales de forma distribuida usando el **algoritmo Gossip** implementado con [Hivemind](https://github.com/learning-at-home/hivemind).

## üìö Contenido

- `src/trainGossipCifar.py` - Entrenamiento de CNN en CIFAR-10 con Gossip
- `src/trainGossipImagenet.py` - Entrenamiento de ResNet50 en ImageNet Tiny con Gossip
- `src/trainGossip.py` - Script base para Tiny ImageNet
- `GOSSIP_ALGORITHM.md` - Documentaci√≥n detallada del algoritmo Gossip
- `test_gossip_args.py` - Tests unitarios para argumentos
- `test_gossip_config.py` - Test de integraci√≥n

## üöÄ Inicio R√°pido

### 1. Instalaci√≥n de Dependencias

```bash
pip install -r requirements.txt
```

### 2. Entrenar con CIFAR-10 (Ejemplo Simple)

**Terminal 1 - Primer Peer (Bootstrap):**
```bash
python src/trainGossipCifar.py \
  --host_maddr /ip4/0.0.0.0/tcp/4011 \
  --batch 64 \
  --epochs 10 \
  --gossip_group_size 8
```

El script imprimir√° algo como:
```
VISIBLE_MADDRS: ['/ip4/192.168.1.100/tcp/4011/p2p/QmXXXXXX...']
```

**Terminal 2 - Segundo Peer:**
```bash
python src/trainGossipCifar.py \
  --initial_peer /ip4/192.168.1.100/tcp/4011/p2p/QmXXXXXX... \
  --host_maddr /ip4/0.0.0.0/tcp/4012 \
  --batch 64 \
  --epochs 10 \
  --gossip_group_size 8
```

**Terminal 3 - Tercer Peer:**
```bash
python src/trainGossipCifar.py \
  --initial_peer /ip4/192.168.1.100/tcp/4011/p2p/QmXXXXXX... \
  --host_maddr /ip4/0.0.0.0/tcp/4013 \
  --batch 64 \
  --epochs 10 \
  --gossip_group_size 8
```

## ‚öôÔ∏è Par√°metros del Algoritmo Gossip

### `--gossip_group_size` (default: 16)
Tama√±o objetivo del grupo para averaging. Determina cu√°ntos peers intentar√°n promediar sus par√°metros juntos en cada ronda.

- **Valores recomendados**: Potencias de 2 (4, 8, 16, 32)
- **Grupos peque√±os (4-8)**: Menos comunicaci√≥n, convergencia m√°s lenta
- **Grupos grandes (16-32)**: M√°s comunicaci√≥n, convergencia m√°s r√°pida

**Ejemplo:**
```bash
--gossip_group_size 8  # Grupos de hasta 8 peers
```

### `--gossip_min_group_size` (default: 2)
N√∫mero m√≠nimo de peers necesarios para comenzar el averaging.

- **Valor bajo (2)**: Permite entrenar con pocos peers
- **Valor alto (4-8)**: Requiere m√°s peers, pero averaging m√°s estable

**Ejemplo:**
```bash
--gossip_min_group_size 2  # Comenzar con al menos 2 peers
```

### `--gossip_alpha` (default: 1.0)
Factor de averaging que controla cu√°nto se mueven los par√°metros locales hacia el promedio del grupo.

- **alpha = 1.0**: Promedio completo (par√°metros locales = promedio del grupo)
- **alpha = 0.5**: Promedio parcial (par√°metros se mueven a medio camino)
- **alpha < 1.0**: Mayor estabilidad, convergencia m√°s lenta

**Ejemplo:**
```bash
--gossip_alpha 0.9  # Averaging suave
```

## üìä Ejemplos de Uso

### CIFAR-10 con 3 Peers

```bash
# Peer 1
python src/trainGossipCifar.py \
  --host_maddr /ip4/0.0.0.0/tcp/4011 \
  --gossip_group_size 4 \
  --gossip_min_group_size 2 \
  --gossip_alpha 1.0 \
  --batch 64 \
  --lr 0.01 \
  --epochs 20

# Peer 2 (usar la VISIBLE_MADDR del Peer 1)
python src/trainGossipCifar.py \
  --initial_peer /ip4/127.0.0.1/tcp/4011/p2p/<PEER_ID> \
  --host_maddr /ip4/0.0.0.0/tcp/4012 \
  --gossip_group_size 4 \
  --batch 64 \
  --lr 0.01 \
  --epochs 20

# Peer 3
python src/trainGossipCifar.py \
  --initial_peer /ip4/127.0.0.1/tcp/4011/p2p/<PEER_ID> \
  --host_maddr /ip4/0.0.0.0/tcp/4013 \
  --gossip_group_size 4 \
  --batch 64 \
  --lr 0.01 \
  --epochs 20
```

### ImageNet Tiny con Averaging Agresivo

```bash
# Configuraci√≥n para convergencia r√°pida con muchos peers
python src/trainGossipImagenet.py \
  --data_root ./data \
  --host_maddr /ip4/0.0.0.0/tcp/5001 \
  --gossip_group_size 32 \
  --gossip_min_group_size 8 \
  --gossip_alpha 1.0 \
  --batch 32 \
  --lr 0.1 \
  --epochs 20
```

### Averaging Conservador (para experimentos)

```bash
# Configuraci√≥n con averaging m√°s suave
python src/trainGossipCifar.py \
  --host_maddr /ip4/0.0.0.0/tcp/4011 \
  --gossip_group_size 8 \
  --gossip_min_group_size 2 \
  --gossip_alpha 0.7 \
  --batch 64 \
  --epochs 30
```

## üî¨ Tests

### Ejecutar Tests de Argumentos
```bash
python test_gossip_args.py
```

Este test verifica que:
- Los argumentos de gossip se parsean correctamente
- Los valores por defecto son correctos
- La configuraci√≥n se pasa a `gossip_averager_opts`

## üìñ M√°s Informaci√≥n

Para una explicaci√≥n detallada del algoritmo Gossip y c√≥mo funciona en Hivemind, consulta:

- **[GOSSIP_ALGORITHM.md](GOSSIP_ALGORITHM.md)** - Documentaci√≥n completa del algoritmo
- **[Hivemind Documentation](https://github.com/learning-at-home/hivemind)** - Documentaci√≥n oficial de Hivemind

## üéØ Ventajas del Algoritmo Gossip

1. **‚úÖ Escalabilidad**: Agregar m√°s peers no sobrecarga la red
2. **‚úÖ Tolerancia a fallos**: Un peer que falla no detiene el entrenamiento
3. **‚úÖ Descentralizaci√≥n**: No hay un √∫nico punto de falla
4. **‚úÖ Eficiencia**: Comunicaci√≥n peer-to-peer directa
5. **‚úÖ Convergencia**: Todos los peers convergen al mismo modelo

## üêõ Troubleshooting

### Error: "Daemon failed to start"
- Aseg√∫rate de tener instalados todos los componentes de hivemind
- Verifica que los puertos no est√©n en uso
- Intenta usar puertos diferentes con `--host_maddr`

### Los peers no se encuentran
- Verifica que la direcci√≥n `--initial_peer` sea correcta (debe incluir `/p2p/<PEER_ID>`)
- Aseg√∫rate de que no haya firewalls bloqueando la comunicaci√≥n
- Verifica que est√©s usando la IP correcta (usa la IP local si est√°s en la misma m√°quina)

### Averaging muy lento
- Aumenta `--gossip_group_size` para averaging m√°s frecuente
- Reduce `--gossip_alpha` para hacer el averaging m√°s gradual
- Aseg√∫rate de tener suficientes peers activos

## üìù Notas

- Los checkpoints se guardan autom√°ticamente en `checkpoints/`
- El mejor modelo se guarda con sufijo `_best.pt`
- El modelo final se guarda con sufijo `_final.pt`
- Usa `--resume_from` para continuar desde un checkpoint

## ü§ù Contribuciones

Para contribuir o reportar issues, visita el repositorio principal.
