{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Distributed ImageNet Training with Hivemind\n",
                "\n",
                "This notebook implements distributed training for ImageNet using ResNet50 and Hivemind DHT."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import multiprocessing as mp\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from tqdm.auto import tqdm\n",
                "import hivemind\n",
                "from torchvision.models import resnet50, ResNet50_Weights\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "from typing import Optional\n",
                "import itertools\n",
                "import warnings\n",
                "import socket\n",
                "import glob\n",
                "import time\n",
                "import requests\n",
                "from google.cloud import storage\n",
                "\n",
                "# Local imports (assuming these files exist in the same directory)\n",
                "from metrics import ResourceMonitor, TrainingLogger\n",
                "from datasets import get_webdataset_loader\n",
                "\n",
                "warnings.filterwarnings(\"ignore\", message=\".*Please use the new API settings to control TF32 behavior.*\")\n",
                "\n",
                "# Set start method for multiprocessing\n",
                "try:\n",
                "    mp.set_start_method('fork', force=True)\n",
                "except RuntimeError:\n",
                "    pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration\n",
                "\n",
                "We use a `Config` class to replace command-line arguments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Config:\n",
                "    def __init__(self):\n",
                "        self.device = None  # Auto-detect\n",
                "        self.initial_peer = None # Multiaddr of initial peer\n",
                "        self.val_every = 1\n",
                "        \n",
                "        # Data loading\n",
                "        self.data_dir = \"gs://caso-estudio-2/imagenet-wds\"\n",
                "        self.num_workers = 0\n",
                "        self.batch_size = 32\n",
                "        self.target_batch_size = 50000\n",
                "        self.val_batches = 100\n",
                "        self.no_initial_val = False\n",
                "        self.epochs = 2000\n",
                "        self.host_port = 31337\n",
                "        \n",
                "        # Hyperparameters\n",
                "        self.lr = 0.001\n",
                "        self.scheduler_milestones = [1000, 1600, 1800]\n",
                "        self.scheduler_gamma = 0.1\n",
                "        \n",
                "        # Automated Peer Discovery\n",
                "        self.announce_gcs_path = None\n",
                "        self.fetch_gcs_path = None\n",
                "\n",
                "args = Config()\n",
                "\n",
                "# Example: Override defaults here if needed\n",
                "# args.batch_size = 32"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_model(num_classes: int = 1000) -> nn.Module:\n",
                "    model = resnet50(weights=None)\n",
                "    in_features = model.fc.in_features\n",
                "    model.fc = nn.Linear(in_features, num_classes)\n",
                "    return model\n",
                "\n",
                "def select_device(cli_device: Optional[str]) -> torch.device:\n",
                "    if cli_device:\n",
                "        return torch.device(cli_device)\n",
                "\n",
                "    # Prefer MPS (Apple Silicon)\n",
                "    mps_available = (\n",
                "        getattr(torch.backends, \"mps\", None) is not None\n",
                "        and torch.backends.mps.is_available()\n",
                "        and torch.backends.mps.is_built()\n",
                "    )\n",
                "    if mps_available:\n",
                "        return torch.device(\"mps\")\n",
                "\n",
                "    if torch.cuda.is_available():\n",
                "        torch.backends.cuda.matmul.allow_tf32 = True\n",
                "        torch.backends.cudnn.allow_tf32 = True\n",
                "        return torch.device(\"cuda\")\n",
                "\n",
                "    return torch.device(\"cpu\")\n",
                "\n",
                "def get_next_log_paths(base_dir=\"stats\"):\n",
                "    hostname = socket.gethostname()\n",
                "    host_dir = os.path.join(base_dir, hostname)\n",
                "    os.makedirs(host_dir, exist_ok=True)\n",
                "\n",
                "    existing_runs = glob.glob(os.path.join(host_dir, \"run_*_system_metrics.csv\"))\n",
                "    max_run = 0\n",
                "    for path in existing_runs:\n",
                "        try:\n",
                "            filename = os.path.basename(path)\n",
                "            parts = filename.split('_')\n",
                "            run_num = int(parts[1])\n",
                "            if run_num > max_run:\n",
                "                max_run = run_num\n",
                "        except (IndexError, ValueError):\n",
                "            continue\n",
                "\n",
                "    next_run = max_run + 1\n",
                "    \n",
                "    sys_metric_path = os.path.join(host_dir, f\"run_{next_run}_system_metrics.csv\")\n",
                "    train_metric_path = os.path.join(host_dir, f\"run_{next_run}_training_metrics.csv\")\n",
                "    \n",
                "    print(f\"üìÅ Logging metrics to: {host_dir} (Run #{next_run})\")\n",
                "    return sys_metric_path, train_metric_path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_accuracy(model: nn.Module, loader, device: torch.device, max_batches: Optional[int] = None) -> tuple:\n",
                "    model_was_training = model.training\n",
                "    model.eval()\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    running_loss = 0.0\n",
                "    num_batches = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        if max_batches is not None:\n",
                "             loader_iter = itertools.islice(loader, max_batches)\n",
                "             total_batches = max_batches\n",
                "        else:\n",
                "             loader_iter = loader\n",
                "             try:\n",
                "                 total_batches = len(loader)\n",
                "             except TypeError:\n",
                "                 if hasattr(loader, 'dataset') and hasattr(loader.dataset, '__len__') and hasattr(loader, 'batch_size'):\n",
                "                     total_batches = len(loader.dataset) // loader.batch_size\n",
                "                 else:\n",
                "                     total_batches = None\n",
                "\n",
                "        for xb, yb in tqdm(loader_iter, total=total_batches, desc=\"Validating\", leave=False):\n",
                "            nb = (device.type == \"cuda\")\n",
                "            xb = xb.to(device, non_blocking=nb)\n",
                "            yb = yb.to(device, non_blocking=nb)\n",
                "            if device.type == \"mps\":\n",
                "                xb = xb.contiguous()\n",
                "\n",
                "            logits = model(xb)\n",
                "            loss = F.cross_entropy(logits, yb)\n",
                "            \n",
                "            running_loss += loss.item()\n",
                "            num_batches += 1\n",
                "            \n",
                "            pred = logits.argmax(dim=1)\n",
                "            correct += (pred == yb).sum().item()\n",
                "            total += yb.size(0)\n",
                "    \n",
                "    avg_loss = running_loss / max(1, num_batches)\n",
                "    accuracy = 100.0 * correct / max(1, total)\n",
                "    \n",
                "    if model_was_training:\n",
                "        model.train()\n",
                "    \n",
                "    return avg_loss, accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer, scheduler, out_dir: str, epoch_idx: int, acc: float, filename: str = \"best_checkpoint.pt\"):\n",
                "    os.makedirs(out_dir, exist_ok=True)\n",
                "    path = os.path.join(out_dir, filename)\n",
                "    torch.save({\n",
                "        \"epoch\": epoch_idx,\n",
                "        \"val_accuracy\": acc,\n",
                "        \"model_state\": model.state_dict(),\n",
                "        \"opt_state\": optimizer.state_dict(),\n",
                "        \"scheduler_state\": scheduler.state_dict() if scheduler else None,\n",
                "    }, path)\n",
                "    return path\n",
                "\n",
                "def load_checkpoint(path: str, model: nn.Module, optimizer: torch.optim.Optimizer, scheduler, device: torch.device):\n",
                "    if not os.path.exists(path):\n",
                "        return None, -1.0\n",
                "\n",
                "    checkpoint = torch.load(path, map_location=device)\n",
                "    model.load_state_dict(checkpoint[\"model_state\"])\n",
                "    optimizer.load_state_dict(checkpoint[\"opt_state\"])\n",
                "    \n",
                "    if scheduler and \"scheduler_state\" in checkpoint and checkpoint[\"scheduler_state\"] is not None:\n",
                "        scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
                "\n",
                "    epoch = checkpoint.get(\"epoch\", 0)\n",
                "    acc = checkpoint.get(\"val_accuracy\", -1.0)\n",
                "\n",
                "    print(f\"‚úì Checkpoint loaded from: {path}\")\n",
                "    print(f\"  Epoch: {epoch}, Accuracy: {acc:.2f}%\")\n",
                "\n",
                "    return epoch, acc"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "RUN_ID = \"imagenet_resnet50\"\n",
                "BATCH = args.batch_size\n",
                "TARGET_GLOBAL_BSZ = args.target_batch_size\n",
                "EPOCHS = args.epochs\n",
                "LR = args.lr\n",
                "MATCHMAKING_TIME = 60.0\n",
                "AVERAGING_TIMEOUT = 120.0\n",
                "CHECKPOINT_DIR = \"./checkpoints\"\n",
                "\n",
                "# Initialize Loggers\n",
                "sys_log_path, train_log_path = get_next_log_paths()\n",
                "resource_monitor = ResourceMonitor(log_file=sys_log_path)\n",
                "resource_monitor.start()\n",
                "training_logger = TrainingLogger(log_file=train_log_path)\n",
                "\n",
                "# Device\n",
                "device = select_device(args.device)\n",
                "print(f\"\\nDevice: {device}\")\n",
                "if device.type == \"mps\":\n",
                "    try:\n",
                "        torch.set_float32_matmul_precision(\"high\")\n",
                "    except Exception:\n",
                "        pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DataLoaders (WebDataset)\n",
                "print(f\"Loading ImageNet from {args.data_dir} (WebDataset)\")\n",
                "\n",
                "# Load ImageNet classes\n",
                "try:\n",
                "    from imagenet_classes import IMAGENET_SYNSETS\n",
                "    classes = IMAGENET_SYNSETS\n",
                "    num_classes = len(classes)\n",
                "    print(f\"Loaded {num_classes} classes from imagenet_classes.py\")\n",
                "except ImportError:\n",
                "    print(\"Could not import imagenet_classes.py. Defaulting to 1000 classes (ImageNet-1k standard).\")\n",
                "    num_classes = 1000\n",
                "    classes = None\n",
                "\n",
                "WORKERS = args.num_workers\n",
                "\n",
                "# Train Loader\n",
                "train_loader = get_webdataset_loader(\n",
                "    bucket_name=args.data_dir,\n",
                "    prefix=\"\",\n",
                "    batch_size=BATCH,\n",
                "    num_workers=WORKERS,\n",
                "    device=device,\n",
                "    is_train=True,\n",
                "    total_shards=641,\n",
                "    train_prefix=\"train/train\",\n",
                "    classes=classes\n",
                ")\n",
                "\n",
                "# Val Loader\n",
                "val_loader = get_webdataset_loader(\n",
                "    bucket_name=args.data_dir,\n",
                "    prefix=\"\",\n",
                "    batch_size=BATCH,\n",
                "    num_workers=WORKERS,\n",
                "    device=device,\n",
                "    is_train=False,\n",
                "    val_shards=50,\n",
                "    val_prefix=\"val/train\",\n",
                "    classes=classes\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Models\n",
                "\n",
                "# MASTER on CPU (for Hivemind)\n",
                "model = build_model(num_classes=num_classes)\n",
                "model = model.to(\"cpu\")\n",
                "\n",
                "# SHADOW on Device (for compute)\n",
                "model_on_device = build_model(num_classes=num_classes)\n",
                "model_on_device = model_on_device.to(device)\n",
                "\n",
                "if device.type == \"cuda\":\n",
                "    model_on_device = model_on_device.to(memory_format=torch.channels_last)\n",
                "\n",
                "# Base Optimizer\n",
                "base_optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Peer Discovery & DHT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Automated Discovery: Fetch\n",
                "if args.fetch_gcs_path and not args.initial_peer:\n",
                "    print(f\"üîç Looking for initial peer address in {args.fetch_gcs_path}...\")\n",
                "    try:\n",
                "        if not args.fetch_gcs_path.startswith(\"gs://\"):\n",
                "            raise ValueError(\"GCS path must start with gs://\")\n",
                "        \n",
                "        parts = args.fetch_gcs_path[5:].split('/', 1)\n",
                "        bucket_name = parts[0]\n",
                "        blob_name = parts[1]\n",
                "        \n",
                "        public_url = f\"https://storage.googleapis.com/{bucket_name}/{blob_name}?t={int(time.time())}\"\n",
                "        print(f\"   Trying public URL: {public_url}\")\n",
                "        \n",
                "        try:\n",
                "            resp = requests.get(public_url, timeout=10)\n",
                "            if resp.status_code == 200:\n",
                "                content = resp.text.strip()\n",
                "                print(f\"‚úÖ Found initial peer: {content}\")\n",
                "                args.initial_peer = content\n",
                "            else:\n",
                "                raise Exception(f\"Status code {resp.status_code}\")\n",
                "        except Exception as e:\n",
                "            print(f\"‚ö†Ô∏è  Could not fetch from public URL ({e}). Trying GCS client...\")\n",
                "            storage_client = storage.Client.create_anonymous_client()\n",
                "            bucket = storage_client.bucket(bucket_name)\n",
                "            blob = bucket.blob(blob_name)\n",
                "            content = blob.download_as_text().strip()\n",
                "            if content:\n",
                "                print(f\"‚úÖ Found initial peer (via Client): {content}\")\n",
                "                args.initial_peer = content\n",
                "            else:\n",
                "                print(\"‚ö†Ô∏è  GCS file found but empty.\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è  Failed to fetch initial peer from GCS: {e}\")\n",
                "        print(\"   Will attempt to start without initial peer (or as standalone).\")\n",
                "\n",
                "# DHT Setup\n",
                "dht_kwargs = dict(\n",
                "    host_maddrs=[f\"/ip4/0.0.0.0/tcp/{args.host_port}\"],\n",
                "    start=True,\n",
                "    await_ready=False\n",
                ")\n",
                "if args.initial_peer:\n",
                "    dht_kwargs[\"initial_peers\"] = [args.initial_peer]\n",
                "\n",
                "print(f\"=== Hivemind DHT ===\")\n",
                "dht = hivemind.DHT(**dht_kwargs)\n",
                "\n",
                "# Automated Discovery: Announce\n",
                "if args.announce_gcs_path:\n",
                "    print(f\"üì¢ Announcing this peer to {args.announce_gcs_path}...\")\n",
                "    try:\n",
                "        try:\n",
                "            public_ip = requests.get('https://checkip.amazonaws.com', timeout=5).text.strip()\n",
                "        except:\n",
                "            public_ip = \"127.0.0.1\"\n",
                "            \n",
                "        peer_id = dht.peer_id\n",
                "        port = args.host_port\n",
                "        full_address = f\"/ip4/{public_ip}/tcp/{port}/p2p/{peer_id}\"\n",
                "        \n",
                "        print(f\"   Public Address: {full_address}\")\n",
                "        \n",
                "        if not args.announce_gcs_path.startswith(\"gs://\"):\n",
                "            raise ValueError(\"GCS path must start with gs://\")\n",
                "            \n",
                "        parts = args.announce_gcs_path[5:].split('/', 1)\n",
                "        bucket_name = parts[0]\n",
                "        blob_name = parts[1]\n",
                "        \n",
                "        storage_client = storage.Client() \n",
                "        bucket = storage_client.bucket(bucket_name)\n",
                "        blob = bucket.blob(blob_name)\n",
                "        \n",
                "        blob.upload_from_string(full_address)\n",
                "        print(f\"‚úÖ Address written to GCS successfully.\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Failed to announce address to GCS: {e}\")\n",
                "\n",
                "# Wait for DHT\n",
                "print(\"‚è≥ Waiting for DHT to be ready...\")\n",
                "try:\n",
                "    dht.wait_until_ready(timeout=60.0)\n",
                "    print(\"DHT is ready!\")\n",
                "except TimeoutError:\n",
                "    print(\"DHT timed out waiting for readiness. Continuing anyway...\")\n",
                "\n",
                "maddrs = [str(m) for m in dht.get_visible_maddrs()]\n",
                "print(\"\\n=== Hivemind DHT ===\")\n",
                "for m in maddrs:\n",
                "    print(\"VISIBLE_MADDR:\", m)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Task exception was never retrieved\n",
                        "future: <Task finished name='Task-62' coro=<DecentralizedAverager._declare_for_download_periodically() done, defined at /home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/hivemind/averaging/averager.py:600> exception=RuntimeError('Broken pipe')>\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/hivemind/averaging/averager.py\", line 609, in _declare_for_download_periodically\n",
                        "    self.dht.store(\n",
                        "    ~~~~~~~~~~~~~~^\n",
                        "        download_key,\n",
                        "        ^^^^^^^^^^^^^\n",
                        "    ...<3 lines>...\n",
                        "        return_future=True,\n",
                        "        ^^^^^^^^^^^^^^^^^^^\n",
                        "    ),\n",
                        "    ^\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/hivemind/dht/dht.py\", line 212, in store\n",
                        "    future = MPFuture()\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/hivemind/utils/mpfuture.py\", line 93, in __init__\n",
                        "    self._shared_state_code = SharedBytes.next()\n",
                        "                              ~~~~~~~~~~~~~~~~^^\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/hivemind/utils/mpfuture.py\", line 52, in next\n",
                        "    cls._buffer = torch.empty([buffer_size], dtype=torch.uint8).share_memory_()\n",
                        "                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/torch/_tensor.py\", line 817, in share_memory_\n",
                        "    self._typed_storage()._share_memory_()\n",
                        "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/torch/storage.py\", line 1195, in _share_memory_\n",
                        "    self._untyped_storage.share_memory_()\n",
                        "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/torch/storage.py\", line 451, in wrapper\n",
                        "    return fn(self, *args, **kwargs)\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/torch/storage.py\", line 522, in share_memory_\n",
                        "    return super().share_memory_(*args, **kwargs)\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/torch/storage.py\", line 400, in share_memory_\n",
                        "    self._share_filename_cpu_()\n",
                        "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/torch/storage.py\", line 451, in wrapper\n",
                        "    return fn(self, *args, **kwargs)\n",
                        "  File \"/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/torch/storage.py\", line 530, in _share_filename_cpu_\n",
                        "    return super()._share_filename_cpu_(*args, **kwargs)\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
                        "RuntimeError: Broken pipe\n"
                    ]
                }
            ],
            "source": [
                "best_accuracy = -1.0\n",
                "start_epoch = 0\n",
                "\n",
                "# Hivemind Optimizer\n",
                "opt = hivemind.Optimizer(\n",
                "    dht=dht,\n",
                "    run_id=RUN_ID,\n",
                "    batch_size_per_step=BATCH,\n",
                "    target_batch_size=TARGET_GLOBAL_BSZ,\n",
                "    optimizer=base_optimizer,\n",
                "    use_local_updates=True,\n",
                "    matchmaking_time=MATCHMAKING_TIME,\n",
                "    averaging_timeout=AVERAGING_TIMEOUT,\n",
                "    verbose=True,\n",
                ")\n",
                "\n",
                "# Scheduler\n",
                "scheduler = torch.optim.lr_scheduler.MultiStepLR(base_optimizer, milestones=args.scheduler_milestones, gamma=args.scheduler_gamma)\n",
                "\n",
                "# Load Checkpoint\n",
                "latest_path = os.path.join(CHECKPOINT_DIR, \"latest_checkpoint.pt\")\n",
                "best_path = os.path.join(CHECKPOINT_DIR, \"best_checkpoint.pt\")\n",
                "\n",
                "if os.path.exists(latest_path):\n",
                "    print(f\"Resuming from LATEST: {latest_path}\")\n",
                "    start_epoch, acc = load_checkpoint(latest_path, model, opt, scheduler, device)\n",
                "    \n",
                "    if os.path.exists(best_path):\n",
                "        checkpoint = torch.load(best_path, map_location='cpu')\n",
                "        best_accuracy = checkpoint.get(\"val_accuracy\", acc)\n",
                "    else:\n",
                "        best_accuracy = acc\n",
                "elif os.path.exists(best_path):\n",
                "    print(f\"Resuming from BEST: {best_path}\")\n",
                "    start_epoch, best_accuracy = load_checkpoint(best_path, model, opt, scheduler, device)\n",
                "else:\n",
                "    print(\"No checkpoints found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Dec 01 14:45:25.789 [\u001b[1m\u001b[34mINFO\u001b[0m] imagenet_resnet50 accumulated 1952 samples for epoch #0 from 1 peers. ETA 32451.42 sec (refresh in 10.00 sec)\n",
                        "/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/webdataset/handlers.py:55: UserWarning: OSError(\"((['curl', '--ipv4', '--http1.1', '--retry', '5', '--retry-delay', '2', '--connect-timeout', '30', '-f', '-s', '-L', 'https://storage.googleapis.com/caso-estudio-2/imagenet-wds/train/train-000494.tar'],), {'bufsize': 8192}): exit -2 (read) {} @ <Pipe ((['curl', '--ipv4', '--http1.1', '--retry', '5', '--retry-delay', '2', '--connect-timeout', '30', '-f', '-s', '-L', 'https://storage.googleapis.com/caso-estudio-2/imagenet-wds/train/train-000494.tar'],), {'bufsize': 8192})>\")\n",
                        "  warnings.warn(repr(exn))\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/distrubuted-ImageNet/neural-network-train/src/datasets.py:374\u001b[39m, in \u001b[36mThreadedWebDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    371\u001b[39m t.start()\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/queue.py:199\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    201\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/daniel/distrubuted-ImageNet/.venv/lib/python3.13/site-packages/webdataset/handlers.py:55: UserWarning: OSError(\"((['curl', '--ipv4', '--http1.1', '--retry', '5', '--retry-delay', '2', '--connect-timeout', '30', '-f', '-s', '-L', 'https://storage.googleapis.com/caso-estudio-2/imagenet-wds/train/train-000494.tar'],), {'bufsize': 8192}): exit -2 (read) {}\", <webdataset.gopen.Pipe object at 0x7f84386f5e50>, 'https://storage.googleapis.com/caso-estudio-2/imagenet-wds/train/train-000494.tar')\n",
                        "  warnings.warn(repr(exn))\n",
                        "terminate called after throwing an instance of 'std::system_error'\n",
                        "  what():  Broken pipe\n"
                    ]
                }
            ],
            "source": [
                "target_epochs = EPOCHS\n",
                "last_seen_epoch = getattr(opt, \"local_epoch\", 0)\n",
                "checkpoint_path = None\n",
                "\n",
                "train_correct = 0\n",
                "train_total = 0\n",
                "\n",
                "print(f\"\\nTraining until {target_epochs} global epochs (target_batch_size={TARGET_GLOBAL_BSZ}).\")\n",
                "if best_accuracy > 0:\n",
                "    print(f\"Continuing from best accuracy: {best_accuracy:.2f}%\")\n",
                "\n",
                "try:\n",
                "    with tqdm(total=None) as pbar:\n",
                "        while True:\n",
                "            for xb, yb in train_loader:\n",
                "                nb = (device.type == \"cuda\")\n",
                "\n",
                "                xb = xb.to(device, non_blocking=nb)\n",
                "                yb = yb.to(device, non_blocking=nb)\n",
                "\n",
                "                # Safety check for labels\n",
                "                if (yb < 0).any() or (yb >= num_classes).any():\n",
                "                    invalid_vals = yb[(yb < 0) | (yb >= num_classes)]\n",
                "                    raise RuntimeError(f\"Found invalid labels in batch: {invalid_vals.cpu().numpy()}. Expected range [0, {num_classes}).\")\n",
                "\n",
                "                if device.type == \"cuda\":\n",
                "                    xb = xb.to(memory_format=torch.channels_last)\n",
                "                elif device.type == \"mps\":\n",
                "                    xb = xb.contiguous()\n",
                "\n",
                "                # 1. Sync weights CPU -> Device\n",
                "                with torch.no_grad():\n",
                "                    for p_cpu, p_dev in zip(model.parameters(), model_on_device.parameters()):\n",
                "                        p_dev.copy_(p_cpu)\n",
                "                    for b_cpu, b_dev in zip(model.buffers(), model_on_device.buffers()):\n",
                "                        b_dev.copy_(b_cpu)\n",
                "\n",
                "                # 2. Forward/Backward on Device\n",
                "                model_on_device.train()\n",
                "                model_on_device.zero_grad()\n",
                "                \n",
                "                logits = model_on_device(xb)\n",
                "                loss = F.cross_entropy(logits, yb)\n",
                "                \n",
                "                # Calculate training accuracy\n",
                "                with torch.no_grad():\n",
                "                    pred = logits.argmax(dim=1)\n",
                "                    train_correct += (pred == yb).sum().item()\n",
                "                    train_total += yb.size(0)\n",
                "                \n",
                "                loss.backward()\n",
                "\n",
                "                # 3. Sync gradients Device -> CPU\n",
                "                with torch.no_grad():\n",
                "                    for p_cpu, p_dev in zip(model.parameters(), model_on_device.parameters()):\n",
                "                        if p_dev.grad is not None:\n",
                "                            if p_cpu.grad is None:\n",
                "                                p_cpu.grad = torch.zeros_like(p_cpu)\n",
                "                            p_cpu.grad.copy_(p_dev.grad)\n",
                "\n",
                "                # 3.5 Sync buffers Device -> CPU\n",
                "                with torch.no_grad():\n",
                "                    for b_cpu, b_dev in zip(model.buffers(), model_on_device.buffers()):\n",
                "                        b_cpu.copy_(b_dev)\n",
                "\n",
                "                # 4. Step on CPU (Hivemind)\n",
                "                opt.step()\n",
                "                opt.zero_grad()\n",
                "                \n",
                "                current_train_acc = 100.0 * train_correct / max(1, train_total)\n",
                "\n",
                "                pbar.set_description(\n",
                "                    f\"loss={loss.item():.4f}  train_acc={current_train_acc:.2f}%  epoch_g={getattr(opt,'local_epoch',0)}  best_val={best_accuracy:.2f}%\"\n",
                "                )\n",
                "                pbar.update()\n",
                "                \n",
                "                # Log training step\n",
                "                current_lr = scheduler.get_last_lr()[0]\n",
                "                training_logger.log_step(\n",
                "                    epoch=getattr(opt, \"local_epoch\", 0),\n",
                "                    batch=pbar.n,\n",
                "                    loss=loss.item(),\n",
                "                    learning_rate=current_lr,\n",
                "                    accuracy=current_train_acc\n",
                "                )\n",
                "\n",
                "                current_epoch = getattr(opt, \"local_epoch\", last_seen_epoch)\n",
                "                if current_epoch != last_seen_epoch:\n",
                "                    # Epoch finished\n",
                "                    final_train_acc = 100.0 * train_correct / max(1, train_total)\n",
                "                    tqdm.write(f\"[Epoch {last_seen_epoch}] Training accuracy: {final_train_acc:.2f}%\")\n",
                "                    \n",
                "                    train_correct = 0\n",
                "                    train_total = 0\n",
                "                    \n",
                "                    force_initial = (current_epoch == 1 and not args.no_initial_val)\n",
                "                    do_eval = force_initial or (current_epoch % args.val_every == 0) or (current_epoch >= target_epochs)\n",
                "                    if do_eval:\n",
                "                        tqdm.write(f\"Starting validation for epoch {current_epoch}...\")\n",
                "                        \n",
                "                        # Sync weights to device before eval\n",
                "                        with torch.no_grad():\n",
                "                            for p_cpu, p_dev in zip(model.parameters(), model_on_device.parameters()):\n",
                "                                p_dev.copy_(p_cpu)\n",
                "                            for b_cpu, b_dev in zip(model.buffers(), model_on_device.buffers()):\n",
                "                                b_dev.copy_(b_cpu)\n",
                "\n",
                "                        val_loss, val_acc = evaluate_accuracy(model_on_device, val_loader, device, max_batches=args.val_batches)\n",
                "                        tqdm.write(f\"[Epoch {current_epoch}] Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
                "                        \n",
                "                        training_logger.log_step(\n",
                "                            epoch=current_epoch,\n",
                "                            batch=pbar.n,\n",
                "                            loss=val_loss,\n",
                "                            learning_rate=scheduler.get_last_lr()[0],\n",
                "                            accuracy=val_acc\n",
                "                        )\n",
                "\n",
                "                        save_checkpoint(model, opt, scheduler, CHECKPOINT_DIR, current_epoch, val_acc, filename=\"latest_checkpoint.pt\")\n",
                "                        \n",
                "                        if val_acc > best_accuracy:\n",
                "                            ckpt_path = save_checkpoint(model, opt, scheduler, CHECKPOINT_DIR, current_epoch, val_acc, filename=\"best_checkpoint.pt\")\n",
                "                            best_accuracy = val_acc\n",
                "                            checkpoint_path = ckpt_path\n",
                "                            tqdm.write(f\"‚Üë New best accuracy ({best_accuracy:.2f}%). Saved: {ckpt_path}\")\n",
                "                        else:\n",
                "                            tqdm.write(f\"‚Üî No improvement (best={best_accuracy:.2f}%).\")\n",
                "\n",
                "                    last_seen_epoch = current_epoch\n",
                "                    scheduler.step()\n",
                "\n",
                "                    if current_epoch >= target_epochs:\n",
                "                        tqdm.write(f\"‚úì Reached {current_epoch} global epochs. Finishing...\")\n",
                "                        raise StopIteration\n",
                "except StopIteration:\n",
                "    pass\n",
                "\n",
                "if checkpoint_path or best_accuracy > 0:\n",
                "    print(f\"\\nTraining finished. Best accuracy: {best_accuracy:.2f}%\")\n",
                "    if checkpoint_path:\n",
                "        print(f\"Best checkpoint: {checkpoint_path}\")\n",
                "else:\n",
                "    print(\"\\nTraining finished. No checkpoints saved.\")\n",
                "\n",
                "resource_monitor.stop()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
